
# **Desafio Pr√°tico - VExpenses**
![Blog-VExpenses](https://github.com/user-attachments/assets/2999509a-0a11-4f80-9600-37ce863e142d)

Este reposit√≥rio foi criado com o objetivo de apresentar o trabalho desenvolvido no estudo de caso para a vaga de est√°gio na √°rea de Ci√™ncia de Dados da empresa VExpenses, especializada em solu√ß√µes de gerenciamento e automa√ß√£o de despesas corporativas.

## ***Introdu√ß√£o***

Este projeto tem como objetivo a cria√ß√£o de um modelo de classifica√ß√£o capaz de prever se um usu√°rio, baseado em suas intera√ß√µes em um site imobili√°rio, comprar√° ou n√£o uma casa. O modelo ser√° treinado utilizando um conjunto de dados que cont√©m informa√ß√µes demogr√°ficas e comportamentais dos usu√°rios, como idade, renda, tempo de navega√ß√£o no site, e intera√ß√£o com an√∫ncios.

O desafio √© usar essas vari√°veis para prever a decis√£o de compra, que √© representada pela vari√°vel alvo "Compra". Com isso, o projeto busca fornecer insights sobre o comportamento dos usu√°rios e como essas caracter√≠sticas influenciam a decis√£o de compra de um im√≥vel.

Ao longo deste reposit√≥rio, apresentamos um passo a passo detalhado do processo de constru√ß√£o do modelo, desde a an√°lise inicial dos dados at√© a avalia√ß√£o do desempenho do modelo final. O objetivo √© fornecer uma abordagem did√°tica para quem deseja aprender sobre t√©cnicas de aprendizado de m√°quina aplicadas a problemas reais de neg√≥cios.

## ***Descri√ß√£o do Projeto***

Este projeto √© um desafio pr√°tico desenvolvido como parte do processo seletivo para uma vaga de est√°gio em Ci√™ncia de Dados. O objetivo √© construir um modelo de classifica√ß√£o para prever se um usu√°rio de um site imobili√°rio comprar√° ou n√£o uma casa, com base em suas caracter√≠sticas demogr√°ficas e comportamentais.

Os dados foram divididos em dois conjuntos:

- **Conjunto de Treinamento**
  - 140 registros
  - Aproximadamente 70% do total
  - Este conjunto ser√° utilizado para treinar o modelo de aprendizado de m√°quina e realizar a valida√ß√£o inicial do desempenho.

- **Conjunto de Teste**
  - 60 registros
  - Aproximadamente 30% do total
  - Este conjunto ser√° utilizado para avaliar a efic√°cia do modelo treinado.

O **conjunto de treinamento** cont√©m dados sobre os usu√°rios e se eles compraram ou n√£o uma casa, informa√ß√µes que ser√£o usadas para treinar o modelo de classifica√ß√£o.

O **conjunto de teste** ser√° utilizado para testar o desempenho do modelo em dados n√£o vistos. Para esse conjunto, as respostas (compra ou n√£o compra) n√£o est√£o fornecidas, e o modelo ser√° respons√°vel por prever esses resultados.

Este projeto visa demonstrar as habilidades de an√°lise de dados, processamento de informa√ß√µes e constru√ß√£o de modelos preditivos, essenciais para o cargo de est√°gio em Ci√™ncia de Dados.

# **Etapas**

Muitos dos passos est√£o explicados diretamente no pr√≥prio Jupyter Notebook. Neste README, fornecerei apenas informa√ß√µes mais gerais sobre as etapas anteriores √† **interpreta√ß√£o dos resultados**, pois darei um foco maior a essa parte aqui.

Ambos os documentos se complementam, portanto, algumas informa√ß√µes presentes nesse README podem n√£o estar no Jupyter Notebook e vice-versa. Por isso, recomendo analisar cada etapa com base em ambos os textos para uma compreens√£o completa.



## ***0. Entendendo o Dataset***

Nesta primeira etapa, o objetivo √© importar as bibliotecas necess√°rias, carregar o dataset e realizar uma an√°lise preliminar para entender melhor os dados com os quais estamos lidando. Isso inclui visualizar as primeiras linhas, verificar os tipos de dados de cada coluna e entender a distribui√ß√£o dos dados. Tamb√©m foi realizado uma an√°lise para identificar valores at√≠picos e valores ausentes.

Dentre as principais atividades realizadas, temos:

- **Importa√ß√£o de Bibliotecas**: Foi usado bibliotecas como Pandas para manipula√ß√£o dos dados, Matplotlib e Seaborn para visualiza√ß√µes, e Scikit-learn para modelagem.
- **Carregamento e Visualiza√ß√£o Inicial**: Foi carregado o dataset e visualizamos as primeiras linhas e tipos de dados de cada coluna.
- An√°lise Descritiva: Tamb√©m foi verificado estat√≠sticas b√°sicas das vari√°veis num√©ricas e a distribui√ß√£o da vari√°vel alvo ("Compra").
- Identifica√ß√£o de Problemas: E por fim, foi investigado a presen√ßa de valores ausentes e poss√≠veis outliers, como valores negativos no "Tempo no Site (min)".

Essa etapa ajudou a entender melhor os dados e a preparar o terreno para uma an√°lise explorat√≥ria mais acertiva.

## ***1. An√°lise Explorat√≥ria de Dados (AED)***

A An√°lise Explorat√≥ria de Dados tem como objetivo obter uma compreens√£o mais profunda dos dados, identificar problemas potenciais e gerar hip√≥teses sobre o comportamento das vari√°veis.

Dentre as principais atividades realizadas, temos:
- **An√°lise das Rela√ß√µes com a Coluna Alvo**: Foram gerados gr√°ficos para analisar a distribui√ß√£o de cada vari√°vel e como ela se relaciona com a vari√°vel alvo Compra.
- **Matriz de Correla√ß√£o**: A correla√ß√£o entre as vari√°veis num√©ricas foi analisada para verificar rela√ß√µes significativas entre elas.
- **Outros Gr√°ficos**: Al√©m disso, gr√°ficos como o scatterplot foram gerados para visualizar melhor as rela√ß√µes entre as vari√°veis.

Al√©m disso, para uma an√°lise mais detalhada e visual, foi utilizada a biblioteca [**ydata-profiling**](https://github.com/ydataai/ydata-profiling). Essa ferramenta automatiza a an√°lise explorat√≥ria, gerando relat√≥rios completos que oferecem insights valiosos sobre o dataset, como distribui√ß√£o das vari√°veis, correla√ß√µes e poss√≠veis problemas. 

## ***2. Pr√©-Processamento***

Ap√≥s a an√°lise explorat√≥ria, a etapa de pr√©-processamento √© fundamental para garantir a qualidade dos dados antes de aplicar modelos de aprendizado de m√°quina. Durante este processo, abordamos tr√™s pontos principais.

### **2.1 Tratamento de valores nulos**

O tratamento de valores nulos √© uma etapa crucial no pr√©-processamento de dados, pois valores ausentes podem impactar diretamente a performance e a precis√£o dos modelos de aprendizado de m√°quina.

Podem gerar problemas como:
- **Perda de Informa√ß√£o**
  - Uma vez que se os valores ausentes forem ignorados, o modelo pode ser treinado com dados incompletos, o que pode levar a resultados imprecisos ou enviesados.
- **Erro de Execu√ß√£o de Algoritmos**
  - Pois, muitos algoritmos de aprendizado de m√°quina n√£o conseguem lidar com valores nulos e podem gerar erros durante o treinamento ou a previs√£o.
- **Impacto nas M√©tricas**
  - Em modelos de regress√£o ou classifica√ß√£o, a presen√ßa de valores nulos pode afetar a an√°lise de erros, tornando as m√©tricas de avalia√ß√£o

Abaixo esta um gr√°fico mostrando alguns dos valores nulos achados no dataset analisado.

![valores_nulos](https://github.com/user-attachments/assets/d051b18c-0802-44d0-b9bc-974663fdd501)

Existem algumas abordagens para lidar com valores nulos.
- **Removendo os Dados Nulos**
O objetivo aqui √© excluir os registros que cont√™m valores nulos.

Essa abordagem √© adequada quando apenas alguns registros est√£o incompletos. No entanto, pode prejudicar a qualidade do modelo, pois, ao remover um registro, tamb√©m perdemos informa√ß√µes valiosas de outras colunas associadas a ele.

- **Imputa√ß√£o de Valores (M√©dia/Mediana/Moda)**
O objetivo √© preencher os registros com valores nulos com alguns valores estimados com base nos dados dispon√≠veis.

Para **vari√°veis num√©ricas**, √© comum substituir os valores nulos pela m√©dia ou pela mediana, dependendo da distribui√ß√£o dos dados.

A **substitui√ß√£o pela m√©dia** √© uma boa op√ß√£o quando os dados seguem uma distribui√ß√£o normal ou sim√©trica e quando n√£o h√° outliers que possam distorcer seu valor, pois a presen√ßa desses extremos pode comprometer a qualidade dos modelos de machine learning.

A **substitui√ß√£o pela mediana**, por outro lado, √© prefer√≠vel quando os dados possuem uma distribui√ß√£o assim√©trica ou desconhecida. Isso ocorre porque a m√©diana √© mais robusta a outliers, impedindo que valores extremos distor√ßam o conjunto de dados, j√° que ela representa o valor central da amostra.

Para **vari√°veis categ√≥ricas**, √© comum substituir os valores nulos pela moda, ou seja, pelo valor mais frequente na vari√°vel. Essa √© uma abordagem r√°pida e eficiente na maioria dos casos.

- **Imputa√ß√£o com Algoritmos de Machine Learning**

Essa √© uma abordagem mais robusta, na qual algoritmos de machine learning s√£o utilizados para prever os valores ausentes com base em outras caracter√≠sticas do conjunto de dados. Para isso, existem t√©cnicas como KNN ou a Regress√£o	Log√≠stica.

Na **imputa√ß√£o por KNN**, os valores ausentes s√£o preenchidos com base nos valores dos vizinhos mais pr√≥ximos, levando em considera√ß√£o as caracter√≠sticas semelhantes entre as amostras.

J√° na **imputa√ß√£o por Regress√£o Log√≠stica**, utiliza-se um modelo de regress√£o log√≠stica para prever os valores ausentes com base nas outras vari√°veis do conjunto de dados.

Essas t√©cnicas podem ser utilizadas quando a quantidade de dados ausentes √© significativamente grande e a imputa√ß√£o simples n√£o √© suficiente para preservar a qualidade do modelo.


### **2.2 Tratamento das Vari√°veis Categ√≥ricas**

A convers√£o de vari√°veis categ√≥ricas em formatos num√©ricos √© uma outra etapa essencial no pr√©-processamento de dados, especialmente quando se trabalha com modelos de aprendizado de m√°quina.

Isso ocorre porque a maioria dos algoritmos de aprendizado de m√°quina exige entradas num√©ricas para realizar c√°lculos e determinar padr√µes. Como por exemplo, c√°lculos de dist√¢ncia, correla√ß√µes entre outras m√©tricas.

Portanto, o objetivo principal desse tratamento √© aprimorar a efici√™ncia dos modelos que ser√£o desenvolvidos.

Devido √† baixa complexidade do dataset e ao fato de estarmos lidando com vari√°veis categ√≥ricas que podem assumir apenas valores bin√°rios, optei por realizar a **codifica√ß√£o direta** dessas vari√°veis. Essa escolha se mostrou eficiente, pois, como as categorias envolvem apenas dois valores poss√≠veis (como, "sim" ou "n√£o", "0" ou "1"), a convers√£o para formato num√©rico pode ser feita diretamente, sem a necessidade de recorrer a t√©cnicas mais complexas, como one-hot encoding.

**One-hot encoding** √© uma t√©cnica amplamente utilizada no tratamento de vari√°veis categ√≥ricas, especialmente quando um atributo pode assumir mais de dois valores poss√≠veis. Essa abordagem consiste em criar uma nova coluna para cada categoria, onde um valor bin√°rio (0 ou 1) indica a presen√ßa ou aus√™ncia de cada categoria para uma observa√ß√£o espec√≠fica.

Seu uso √© fundamental nesses casos, pois evita que os modelos interpretem erroneamente a exist√™ncia de uma ordem ou rela√ß√£o hier√°rquica entre os valores transformados, o que poderia distorcer os resultados.

### **2.3 Tratamento de Valores Inconsistentes**

Essa etapa, √© fundamental no pr√©-processamento de dados, pois, assim como nos casos anteriores, valores err√¥neos ou que n√£o fazem sentido podem comprometer a qualidade e a confiabilidade do modelo de aprendizado de m√°quina.

Entre os tipos mais comuns de inconsist√™ncias est√£o os valores negativos em vari√°veis onde esses valores n√£o deveriam existir, como em idade, pre√ßo, quantidade de produtos vendidos, entre outros.

Normalmente, valores negativos nessas vari√°veis indicam erros de coleta, falhas de entrada ou dados corrompidos, e sua presen√ßa pode gerar resultados distorcidos durante o treinamento do modelo. Portanto, √© crucial identificar e corrigir esses valores antes de alimentar o modelo.

Como abordagens para lidar com esses casos, podemos **substituir os valores inconsistentes** por valores v√°lidos, como a m√©dia ou a mediana. Outra alternativa √© optar pela **remo√ß√£o dos registros** que cont√™m esses valores inconsistentes. Uma abordagem adicional, embora menos utilizada devido √† complexidade em determinadas situa√ß√µes, √© **consultar o provedor dos dados** para verificar se a inconsist√™ncia √©, de fato, um erro ou n√£o.

No caso desse projeto, foi observado a presen√ßa de valores negativos na coluna ***"Tempo no Site (min)"***, o que claramente n√£o faz sentido, j√° que o tempo de navega√ß√£o em um site n√£o pode ser negativo.

A abordagem adotada foi substituir os valores negativos por valores nulos (NaN) e, em seguida, realizar a substitui√ß√£o desses valores nulos pela **mediana**. A escolha da mediana foi feita com base no que foi comentado anteriormente, j√° que ela √© mais robusta a valores extremos e outliers, garantindo uma imputa√ß√£o mais confi√°vel e representativa do tempo que um usu√°rio fica no site, sem ser influenciada por poss√≠veis distor√ß√µes nos dados. 

Essa estrat√©gia assegura que os dados sejam consistentes e apropriados para a modelagem, melhorando a qualidade do modelo de aprendizado de m√°quina.

Por exemplo, imagine que a coluna "Tempo no Site (min)" contenha um valor muito alto, como 1000 minutos, o que poderia ser um outlier.
- Nesse caso, a **m√©dia** seria influenciada por esse valor extremo, tornando-a maior em rela√ß√£o aos demais valores da coluna.
- J√° a **mediana**, por outro lado, continuaria refletindo de maneira mais fiel o comportamento central dos dados, pois n√£o √© impactada pelos eventuais outliers.


## ***3. Constru√ß√£o do Modelo de Machine Learning***

Nesta etapa, o foco √© construir e treinar o modelo de machine learning para resolver o problema proposto. Ap√≥s o tratamento dos dados, incluindo a remo√ß√£o e substitui√ß√£o de valores nulos, al√©m da transforma√ß√£o das vari√°veis categ√≥ricas, o pr√≥ximo passo √© selecionar o modelo adequado para obter o melhor desempenho.

Para a constru√ß√£o do modelo de machine learning, adotei uma abordagem comparativa, utilizando diferentes algoritmos de classifica√ß√£o para avaliar qual oferece o melhor desempenho para o problema em quest√£o.

Para isso, foram utilizados quatro modelos para a classifica√ß√£o: 
- **Regress√£o Log√≠stica**
- **√Årvore de Decis√£o**
- **Random Forest**  
- **Rede Neural**

A escolha da rede neural foi feita para analisar os resultados utilizando um modelo de maior complexidade em compara√ß√£o com os demais, a fim de verificar se h√° diferen√ßas significativas nos resultados obtidos.

Dividi essa etapa em duas abordagens. Primeiro, realizaremos a previs√£o sem o uso do m√©todo de valida√ß√£o cruzada. Em seguida, aplicaremos o m√©todo de valida√ß√£o cruzada e compararemos os resultados obtidos em ambos os casos.

### **3.1 Previs√£o sem Valida√ß√£o Cruzada**
Nesta etapa, foram realizados os seguintes passos para gerar os modelos:

- **Separa√ß√£o das vari√°veis independentes e da vari√°vel alvo**: Organizando os dados para identificar as vari√°veis explicativas e a vari√°vel a ser prevista.
- **Divis√£o dos dados em treino e teste**: Os dados foram divididos em 70% para treinamento e 30% para teste. Embora n√£o exista uma divis√£o fixa, essa √© a propor√ß√£o mais comum utilizada.
- **Treinamento dos quatro modelos selecionados**: Os modelos foram treinados com base no conjunto de dados de treinamento.
- **Avalia√ß√£o da performance dos modelos**: A performance dos modelos foi avaliada utilizando o conjunto de teste, a fim de verificar como eles se comportam com dados novos
- **Exibi√ß√£o dos relat√≥rios de classifica√ß√£o**: Foram gerados relat√≥rios contendo as m√©tricas de avalia√ß√£o, como precis√£o, recall, F1-score e acur√°cia, para uma an√°lise detalhada do desempenho de cada modelo.

Ap√≥s a conclus√£o desses passos, foi gerado um gr√°fico exibindo os resultados de acur√°cia obtidos pelos modelos, como pode ser observado a seguir.

![resultados_sem_cv](https://github.com/user-attachments/assets/6273ae19-445d-492f-8efe-3eb789bda7d9)


Podemos ver que o modelo que apresentou o ***melhor desempenho*** foi a **√Årvore de Decis√£o**, que obteve a maior acur√°cia entre todos os modelos testados. Isso sugere que a simplicidade e a capacidade de interpreta√ß√£o dessa t√©cnica foram vantajosas para este conjunto de dados, permitindo que ela capturasse de forma eficaz as rela√ß√µes entre as vari√°veis.

Os modelos que apresentaram os ***piores desempenhos*** foram o **Random Forest** e a **Rede Neural (MLP)**. Ambos ficaram atr√°s da √Årvore de Decis√£o em termos de acur√°cia. Isso pode indicar que, neste caso espec√≠fico, esses modelos mais complexos n√£o se ajustaram t√£o bem aos dados ou que a configura√ß√£o dos par√¢metros pode n√£o ter sido a mais adequada, o que comprometeu sua capacidade de generaliza√ß√£o para o conjunto de teste.

### **3.2 Previs√£o com Valida√ß√£o Cruzada**

A valida√ß√£o cruzada √© uma t√©cnica utilizada em aprendizado de m√°quina para avaliar a performance de um modelo de forma mais robusta. Ela tem como objetivo reduzir a varia√ß√£o nos resultados e garantir que o modelo n√£o esteja superajustado (overfitted) aos dados de treinamento.

O termo **underfitting**, √© usado quando um modelo √© muito simples para capturar os padr√µes e rela√ß√µes presentes nos dados. Isso acontece geralmente quando o modelo n√£o possui complexidade suficiente para aprender as caracter√≠sticas subjacentes dos dados, o que leva a um desempenho fraco tanto no conjunto de treinamento quanto no conjunto de teste.

J√° o termo **overfitting**, √© usado quando o modelo "aprende demais" os detalhes dados de treinamento, capturando at√© padr√µes irrelevantes ou espec√≠ficos demais para esse conjunto de dados. Essa caracter√≠sticas, que a princ√≠pio parece ser positiva, faz com que o modelo tenha um desempenho muito bom no conjunto de treinamento, mas se saia mal no conjunto de teste, isso √©, o modelo se adapta excessivamente aos dados de treinamento, tornando-se muito espec√≠fico e, portanto, menos eficaz quando exposto a dados desconhecidos.

Logo, a valida√ß√£o cruzada √© uma das t√©cnicas usadas pare resolver esse problema.

#### **3.2.1 Funcionamento da Valida√ß√£o Cruzada***

Na valida√ß√£o cruzada, o conjunto de dados √© dividido em m√∫ltiplos subconjuntos, os chamados ***folds***.

O conjunto de dados √© dividido em **k folds** de tamanho aproximadamente igual, para cada uma das k itera√ß√µes, o modelo √© treinado em **k-1 folds** e testado no fold restante. Isso √©, ele √© treinado k vezes, utilizando um fold diferente como conjunto de teste a cada vez

O desempenho do modelo √© avaliado em cada itera√ß√£o, e ao final, as m√©tricas de desempenho s√£o **m√©dia das avalia√ß√µes** de todas as itera√ß√µes.

Essa abordagem √© extremamente interessante, pois nos permite ter um maior controle sobre eventuais distor√ß√µes que poderiam ocorrer devido a uma √∫nica divis√£o de dados entre treino e teste. Ao realizar a valida√ß√£o cruzada, temos v√°rias divis√µes dos dados, o que reduz significativamente o risco de uma divis√£o espec√≠fica, que poderia beneficiar ou prejudicar o modelo, tornando-o enviesado.

Com mais separa√ß√µes dos dados, garantimos que o modelo seja avaliado em diferentes contextos e condi√ß√µes, o que ajuda a obter uma medida mais confi√°vel e generaliz√°vel de seu desempenho. Isso torna a avalia√ß√£o do modelo mais robusta, pois evitamos que o desempenho do modelo seja afetado por uma divis√£o particular que poderia n√£o ser representativa do comportamento real dos dados.

Esse tipo de valida√ß√£o cruzada tem o nome de ***k-fold cross-validation***.

#### **3.2.2 Etapas**

As etapas seguem basicamente a mesma estrutura da etapa anterior, com algumas mudan√ßas pontuais. Entretanto, etapas como a separa√ß√£o das vari√°veis e a divis√£o entre treino e teste n√£o s√£o realizadas de maneira expl√≠cita, como na etapa anterior. 

Isso ocorre porque podemos reutilizar a separa√ß√£o das vari√°veis, e, ao tratar-se de valida√ß√£o cruzada, a pr√≥pria fun√ß√£o ***cross_val_score()*** ser√° respons√°vel por dividir os dados em treino e teste automaticamente, al√©m de calcular e retornar a acur√°cia m√©dia durante o processo de valida√ß√£o cruzada.

Ap√≥s a conclus√£o desses passos, foi gerado um gr√°fico exibindo os resultados de acur√°cia obtidos pelos modelos, como pode ser observado a seguir.

![resultado_com_cv](https://github.com/user-attachments/assets/6e7ae7f3-37ec-402d-854b-eca90046c75b)

Podemos obervar que o modelo que apresentou o **melhor desempenho** nesse novo contexto foi a **Rede Neural (MLP)**, obtendo a maior acur√°cia entre os demais. 

J√° o modelo que apresentou o **pior desempenho** foi a **√Årvore de Decis√£o**, obtendo a pior acur√°cia.

### **3.3 Compara√ß√£o**

Uma vez realizada ambas abordagens, vamos analisar um pouco as diferen√ßas obtidas.

![comparacao](https://github.com/user-attachments/assets/3f15f254-2439-4cc1-beb5-82114a468592)

Uma observa√ß√£o interessante √© que os pap√©is dos modelos se inverteram ao utilizarmos a valida√ß√£o cruzada na constru√ß√£o dos modelos. 

Enquanto, ***sem a valida√ß√£o cruzada***, o melhor modelo era a **√Årvore de Decis√£o** e o pior modelo era a **Rede Neural**, com a introdu√ß√£o da ***valida√ß√£o cruzada***, a **√Årvore de Decis√£o** passou a ter o pior desempenho, enquanto a **Rede Neural** se destacou como o melhor modelo.

Esse fen√¥meno pode ser explicado pelo fato de que a valida√ß√£o cruzada oferece uma avalia√ß√£o mais robusta e generalizada do desempenho dos modelos. Ela permite que o modelo seja testado em diferentes divis√µes dos dados, reduzindo o risco de sobreajuste (overfitting) e proporcionando uma avalia√ß√£o mais fiel √† sua capacidade de generaliza√ß√£o

Assim, enquanto a **√Årvore de Decis√£o** pode ter se beneficiado de uma divis√£o espec√≠fica dos dados, a **Rede Neural**, com sua capacidade de capturar padr√µes mais complexos, teve seu potencial melhor aproveitado e mostrou-se mais eficaz com a valida√ß√£o cruzada.

Logo, podemos dizer que no caso dos modelos sem valida√ß√£o
cruzada a **√Årvore de Decis√£o** pode ter se sa√≠do melhor porque se ajustou bem aos dados de treino espec√≠ficos, sem a preocupa√ß√£o de generalizar em diferentes conjuntos de dados. Isso pode ter dado uma falsa sensa√ß√£o de bom desempenho.

J√° com a valida√ß√£o cruzada, a **Rede Neural** mostrou sua capacidade de generaliza√ß√£o, uma vez que foi exigida uma avalia√ß√£o mais rigorosa e robusta do desempenho do modelo.


## ***4. Ajustando Hiperpar√¢metros***

## üõ† Ferramentas
- Python 
- Bibliotecas 
    - Pandas
    - NumPy
    - YData Profiling
    - Scikit Learn 
    - Seaborn
    - Matplotlib
## Refer√™ncias

- [Pandas](https://pandas.pydata.org/)
- [NumPy](https://numpy.org/)
- [YData Profiling](https://github.com/ydataai/ydata-profiling)
- [Scikit Learn](https://scikit-learn.org/stable/index.html)
- [Seaborn](https://seaborn.pydata.org/)
- [Matplotlib](https://matplotlib.org/)


## Autor

- [@pedrohspassos](https://github.com/pedrohspassos)

